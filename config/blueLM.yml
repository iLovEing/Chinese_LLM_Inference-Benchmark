paths:
  model_name_or_path:
    win: vivo-ai/BlueLM-7B-Base
    linux: vivo-ai/BlueLM-7B-Chat  # vivo-ai/BlueLM-7B-Base-32K, vivo-ai/BlueLM-7B-Chat, vivo-ai/BlueLM-7B-Chat-32K
  save_root_dir:
    win: result
    linux: result

# behavior
benchmark: CMMLU
model: BlueLM  # model-benchmark class name
do_benchmark: true
do_test_infer: false

# generate_config, only take effect at generate mode
skip_special_tokens: true  # set true to avoid show special_tokens such as pad_token when decoding
max_new_tokens: 200
do_sample: True
num_beams: 3
temperature: 0.9
top_p: 0.75
top_k: 50
generate_input:
  - '请介绍一下你自己。'
  - '你的中文能力怎么样'
  - '1+1等于几？'
  - '求解方程: 3x + 10 = 13, 请按步骤一步一步求解答案。'
  - '笼子里有若干只鸡和兔，从上面数有8个头，从下面数有20只脚，鸡和兔各有多少只？请一步一步求解答案。'

# benchmark_config, only take effect at benchmark mode
few_shot: 5  # set 0 means zero-shot
random_shot: true
max_length: 4096
batch_size: 4
strict_bhm: false
force_refresh: false

