paths:
  model_name_or_path:
    win: meta-llama/Llama-3.1-8B-Instruct
    linux: meta-llama/Llama-3.1-8B-Instruct
  result_dir:
    win: result
    linux: result

# behavior
benchmark: CMMLU
model: Llama3  # model-benchmark class name
load_in_8bit: false
do_benchmark: false
do_test_infer: true

# generate_config, only take effect at generate mode
skip_special_tokens: true  # set true to avoid show special_tokens such as pad_token
max_new_tokens: 512
do_sample: True
num_beams: 5
temperature: 0.9
top_p: 0.75
top_k: 50
generate_input:
  - '你是谁？你的中文能力怎么样？'
  - '北上广深指的是中国的哪几个城市？'
  - '世界上最高的山峰是哪座？海拔多少米？'
  - '笼子里有若干只鸡和兔，从上面数有8个头，从下面数有20只脚，鸡和兔各有多少只？请一步一步求解答案。'
  - '求解方程: x^2 + 4x - 5 = 0, 请用求根公式和因式分解两种方法求解，并写出解题步骤。'

# benchmark_config, only take effect at benchmark mode
few_shot: 5  # set 0 means zero-shot
random_shot: true
max_length: 4096
batch_size: 6
strict_bhm: false  # strict: use the output of last token to match label, otherwise use the highest logits of add choices
force_refresh: false



