# Benchmark Summary
|          model          |  CEval   |  CMMLU   |
| ----------------------- | -------- | -------- |
|    glm-4-9b-chat-hf     |  69.24   |  69.37   |
|   qwen2.5-7B-Instruct   |  77.42   |  80.42   |
|     blueLM-7B-Chat      |  71.84   |  76.56   |
|         random          |  24.89   |  25.59   |
|  llama3.1-8B-Instruct   |  43.16   |  55.90   |